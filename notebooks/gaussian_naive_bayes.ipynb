{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feat-1</th>\n",
       "      <th>Feat-2</th>\n",
       "      <th>Feat-3</th>\n",
       "      <th>Feat-4</th>\n",
       "      <th>Feat-5</th>\n",
       "      <th>Feat-6</th>\n",
       "      <th>Feat-7</th>\n",
       "      <th>Feat-8</th>\n",
       "      <th>Feat-9</th>\n",
       "      <th>Feat-10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat-22</th>\n",
       "      <th>Feat-23</th>\n",
       "      <th>Feat-24</th>\n",
       "      <th>Feat-25</th>\n",
       "      <th>Feat-26</th>\n",
       "      <th>Feat-27</th>\n",
       "      <th>Feat-28</th>\n",
       "      <th>Feat-29</th>\n",
       "      <th>Feat-30</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.412963</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>-0.953418</td>\n",
       "      <td>0.798840</td>\n",
       "      <td>0.658006</td>\n",
       "      <td>0.768405</td>\n",
       "      <td>-0.405588</td>\n",
       "      <td>-0.442541</td>\n",
       "      <td>-0.001558</td>\n",
       "      <td>1.049287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.646514</td>\n",
       "      <td>0.860895</td>\n",
       "      <td>-2.411875</td>\n",
       "      <td>0.994851</td>\n",
       "      <td>1.025006</td>\n",
       "      <td>0.579802</td>\n",
       "      <td>0.803897</td>\n",
       "      <td>0.904436</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.591946</td>\n",
       "      <td>1.210280</td>\n",
       "      <td>1.718345</td>\n",
       "      <td>3.053790</td>\n",
       "      <td>-1.179496</td>\n",
       "      <td>1.109550</td>\n",
       "      <td>0.775757</td>\n",
       "      <td>0.153515</td>\n",
       "      <td>-0.001558</td>\n",
       "      <td>0.555115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>1.478546</td>\n",
       "      <td>1.046527</td>\n",
       "      <td>0.503741</td>\n",
       "      <td>1.002365</td>\n",
       "      <td>0.842098</td>\n",
       "      <td>0.713030</td>\n",
       "      <td>0.777919</td>\n",
       "      <td>1.009964</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.907598</td>\n",
       "      <td>0.455454</td>\n",
       "      <td>-1.252488</td>\n",
       "      <td>0.215091</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>2.519551</td>\n",
       "      <td>0.292663</td>\n",
       "      <td>-0.001558</td>\n",
       "      <td>0.460814</td>\n",
       "      <td>...</td>\n",
       "      <td>3.111020</td>\n",
       "      <td>0.886526</td>\n",
       "      <td>0.740503</td>\n",
       "      <td>1.110159</td>\n",
       "      <td>0.998776</td>\n",
       "      <td>0.704871</td>\n",
       "      <td>0.493281</td>\n",
       "      <td>0.594564</td>\n",
       "      <td>0.580279</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.891311</td>\n",
       "      <td>-1.178866</td>\n",
       "      <td>1.035310</td>\n",
       "      <td>1.221389</td>\n",
       "      <td>1.481984</td>\n",
       "      <td>0.804590</td>\n",
       "      <td>1.561999</td>\n",
       "      <td>-0.699774</td>\n",
       "      <td>-0.001558</td>\n",
       "      <td>0.649795</td>\n",
       "      <td>...</td>\n",
       "      <td>3.111020</td>\n",
       "      <td>1.082386</td>\n",
       "      <td>0.928540</td>\n",
       "      <td>-0.060958</td>\n",
       "      <td>0.988557</td>\n",
       "      <td>0.699047</td>\n",
       "      <td>0.974086</td>\n",
       "      <td>1.213914</td>\n",
       "      <td>1.480364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.550914</td>\n",
       "      <td>-0.886675</td>\n",
       "      <td>1.014226</td>\n",
       "      <td>0.666486</td>\n",
       "      <td>-0.244051</td>\n",
       "      <td>0.763458</td>\n",
       "      <td>-0.730383</td>\n",
       "      <td>-1.467584</td>\n",
       "      <td>2.171518</td>\n",
       "      <td>0.957251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.915975</td>\n",
       "      <td>0.941412</td>\n",
       "      <td>0.527787</td>\n",
       "      <td>1.308168</td>\n",
       "      <td>1.022230</td>\n",
       "      <td>0.592647</td>\n",
       "      <td>0.897614</td>\n",
       "      <td>0.927630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feat-1    Feat-2    Feat-3    Feat-4    Feat-5    Feat-6    Feat-7  \\\n",
       "0  0.412963  0.577200 -0.953418  0.798840  0.658006  0.768405 -0.405588   \n",
       "1  0.591946  1.210280  1.718345  3.053790 -1.179496  1.109550  0.775757   \n",
       "2  1.907598  0.455454 -1.252488  0.215091  0.001179  0.489095  2.519551   \n",
       "3  1.891311 -1.178866  1.035310  1.221389  1.481984  0.804590  1.561999   \n",
       "4  1.550914 -0.886675  1.014226  0.666486 -0.244051  0.763458 -0.730383   \n",
       "\n",
       "     Feat-8    Feat-9   Feat-10  ...   Feat-22   Feat-23   Feat-24   Feat-25  \\\n",
       "0 -0.442541 -0.001558  1.049287  ...  0.009059  0.646514  0.860895 -2.411875   \n",
       "1  0.153515 -0.001558  0.555115  ...  0.009059  1.478546  1.046527  0.503741   \n",
       "2  0.292663 -0.001558  0.460814  ...  3.111020  0.886526  0.740503  1.110159   \n",
       "3 -0.699774 -0.001558  0.649795  ...  3.111020  1.082386  0.928540 -0.060958   \n",
       "4 -1.467584  2.171518  0.957251  ...  0.009059  0.915975  0.941412  0.527787   \n",
       "\n",
       "    Feat-26   Feat-27   Feat-28   Feat-29   Feat-30  Target  \n",
       "0  0.994851  1.025006  0.579802  0.803897  0.904436     0.0  \n",
       "1  1.002365  0.842098  0.713030  0.777919  1.009964     0.0  \n",
       "2  0.998776  0.704871  0.493281  0.594564  0.580279     0.0  \n",
       "3  0.988557  0.699047  0.974086  1.213914  1.480364     0.0  \n",
       "4  1.308168  1.022230  0.592647  0.897614  0.927630     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read train.csv\n",
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train['Target'].to_numpy()\n",
    "train = train.drop('Target', axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard normalize the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train = scaler.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and val\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val, labels_train, labels_val = train_test_split(train, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set:  0.600875\n",
      "Accuracy on validation set:  0.5999916666666667\n",
      "Loss on train set:  0.7928948945747527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/candy/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "/home/candy/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on validation set:  0.79126035045811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.34      0.44     56399\n",
      "         1.0       0.59      0.83      0.69     63601\n",
      "\n",
      "    accuracy                           0.60    120000\n",
      "   macro avg       0.61      0.59      0.56    120000\n",
      "weighted avg       0.61      0.60      0.57    120000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train, labels_train)\n",
    "\n",
    "# accuracy on train and validation set\n",
    "print('Accuracy on train set: ', gnb.score(train, labels_train))\n",
    "print('Accuracy on validation set: ', gnb.score(val, labels_val))\n",
    "\n",
    "# loss on train and validation set\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print('Loss on train set: ', log_loss(labels_train, gnb.predict_proba(train)))\n",
    "print('Loss on validation set: ', log_loss(labels_val, gnb.predict_proba(val)))\n",
    "\n",
    "# precision, recall, f1-score on validation set\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels_val, gnb.predict(val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/candy/.local/lib/python3.10/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 30 features, but StandardScaler is expecting 31 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/candy/acads/ml/assignment/experiments/gaussian_naive_bayes.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/candy/acads/ml/assignment/experiments/gaussian_naive_bayes.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mtest.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/candy/acads/ml/assignment/experiments/gaussian_naive_bayes.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mID\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto_numpy()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/candy/acads/ml/assignment/experiments/gaussian_naive_bayes.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform(test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/candy/acads/ml/assignment/experiments/gaussian_naive_bayes.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# predictions = gnb.predict(test)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/candy/acads/ml/assignment/experiments/gaussian_naive_bayes.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# print(predictions)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/candy/acads/ml/assignment/experiments/gaussian_naive_bayes.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# # write predictions to csv file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/candy/acads/ml/assignment/experiments/gaussian_naive_bayes.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# submission = pd.DataFrame()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/candy/acads/ml/assignment/experiments/gaussian_naive_bayes.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# submission['Id'] = np.arange(1, 10001)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/candy/acads/ml/assignment/experiments/gaussian_naive_bayes.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# submission['Target'] = predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1006\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1003\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m   1005\u001b[0m copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[0;32m-> 1006\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1007\u001b[0m     X,\n\u001b[1;32m   1008\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1009\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1010\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1011\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m   1012\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[1;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(X):\n\u001b[1;32m   1016\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 626\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    628\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 415\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 30 features, but StandardScaler is expecting 31 features as input."
     ]
    }
   ],
   "source": [
    "# generate predictions on test set\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test = test.drop('ID', axis=1).to_numpy()\n",
    "test = scaler.transform(test)\n",
    "\n",
    "# predictions = gnb.predict(test)\n",
    "# print(predictions)\n",
    "# # write predictions to csv file\n",
    "# submission = pd.DataFrame()\n",
    "# submission['Id'] = np.arange(1, 10001)\n",
    "# submission['Target'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
